#!/bin/bash
set -euo pipefail
total_time_start=$(date +%s.%N)

# –ò–ù–°–¢–†–£–ö–¶–ò–Ø –ü–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ:
# –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç:
# -c <–ø—É—Ç—å>  –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ config.sh
#
# –§–ª–∞–≥–∏ –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞ —ç—Ç–∞–ø–æ–≤:
# -s  –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞–º–ø–∞ –ë–î
# -r  –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –æ—á–∏—Å—Ç–∫—É —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
# -t  –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î –∏ –≤—ã–π—Ç–∏ (dry-run)

# ==================== –ü–ê–†–°–ò–ù–ì –ê–†–ì–£–ú–ï–ù–¢–û–í ====================
SKIP_DUMP=false
SKIP_CLEAN=false
DRY_RUN=false
CONFIG_FILE=""

while getopts ":c:srt" opt; do
    case $opt in
        c) CONFIG_FILE="$OPTARG" ;;
        s) SKIP_DUMP=true ;;
        r) SKIP_CLEAN=true ;;
        t) DRY_RUN=true ;;
        \?) echo "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: $0 -c <–ø—É—Ç—å –∫ config.sh> [-s] [-r] [-t]" >&2; exit 1 ;;
    esac
done

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∞—Ä–≥—É–º–µ–Ω—Ç–∞
[ -z "$CONFIG_FILE" ] && { echo "‚ùå –û—à–∏–±–∫–∞: –ù–µ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å –∫ config.sh" >&2; exit 1; }
[ ! -f "$CONFIG_FILE" ] && { echo "‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª config.sh –Ω–µ –Ω–∞–π–¥–µ–Ω: $CONFIG_FILE" >&2; exit 1; }

# ==================== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ====================
SCRIPT_DIR=$(dirname "$(readlink -f "$CONFIG_FILE")")
source "$CONFIG_FILE"

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
HOSTNAME=$(hostname)
BACKUP_DATE=$(date +%Y-%m-%d)
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_NAME="backup_${DB_HOST}_${TIMESTAMP}"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
LOG_DIR="/var/log/backups/${DATABASE}/$(date +%Y-%m)"
mkdir -p "$LOG_DIR"
LOG_FILE="${LOG_DIR}/${BACKUP_NAME}.log"
JSON_LOG="${LOG_DIR}/${BACKUP_NAME}_events.json"
METRICS_LOG="${LOG_DIR}/${BACKUP_NAME}_metrics.json"

# –ü—É—Ç–∏ –¥–ª—è —Ñ–∞–π–ª–æ–≤
TMP_DIR="${SCRIPT_DIR}/tmp"
DUMP_DIR="${SCRIPT_DIR}/dump"
ARCHIVE_DIR="${SCRIPT_DIR}/dump_archive"
SOURCE_DUMP="${DUMP_DIR}/${DATABASE}.bac"
SOURCE="${ARCHIVE_DIR}/${DATABASE}-${BACKUP_DATE}.bac"
ARCHIVE_FILE="${TMP_DIR}/${BACKUP_NAME}.tar.gz"
ENCRYPTED_FILE="${TMP_DIR}/${BACKUP_NAME}.enc"

# Telegram Notifications
TG_BOT_TOKEN="7627195198:AAGD3W0IFbk4Ebn23Zfnd1BkgfTYHy_as5s"
TG_CHAT_ID="-1002682982923"
TG_API_URL="https://api.telegram.org/bot${TG_BOT_TOKEN}/sendMessage"

# ==================== –§–£–ù–ö–¶–ò–ò ====================

# –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å —Ñ–∏–∫—Å–æ–º –¥–ª—è –¥—Ä–æ–±–Ω—ã—Ö —á–∏—Å–µ–ª
format_duration() {
    local seconds=$1
    LC_NUMERIC="en_US.UTF-8" printf "%.2f" "$seconds" | sed 's/,/./'
}

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ JSON –∏–∑ –∞—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω–æ–≥–æ –º–∞—Å—Å–∏–≤–∞
prepare_metrics_json() {
    local -n metrics_ref=$1
    echo "{"
    local first=true
    for key in "${!metrics_ref[@]}"; do
        if ! $first; then
            echo ","
        fi
        printf '"%s": ' "$key"
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∑–Ω–∞—á–µ–Ω–∏—è
        if [[ ${metrics_ref[$key]} =~ ^[0-9]+(\.[0-9]+)?$ ]]; then
            printf "%s" "${metrics_ref[$key]}"
        elif [[ ${metrics_ref[$key]} == "true" || ${metrics_ref[$key]} == "false" ]]; then
            printf "%s" "${metrics_ref[$key]}"
        else
            printf '"%s"' "${metrics_ref[$key]}"
        fi
        first=false
    done
    echo -e "\n}"
}

log() {
    local level=$1
    local message=$2
    local timestamp=$(date '+%Y-%m-%dT%H:%M:%S%z')
    
    # –¢–µ–∫—Å—Ç–æ–≤—ã–π –ª–æ–≥
    echo -e "[${timestamp}] ${level^^} ${message}" | tee -a "$LOG_FILE"
    
    # JSON –ª–æ–≥ –¥–ª—è –≤–∞–∂–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π
    if [[ "$level" == "error" || "$level" == "warning" || "$level" == "info" ]]; then
        jq -n \
            --arg ts "$timestamp" \
            --arg lvl "${level^^}" \
            --arg msg "$message" \
            --arg host "$DB_HOST" \
            --arg db "$DATABASE" \
            '{
                timestamp: $ts,
                level: $lvl,
                db_host: $host,
                db_name: $db,
                message: $msg
            }' >> "$JSON_LOG"
    fi
}

save_metrics() {
    METRICS[end_time]=$(date +%s.%N)
    METRICS[duration]=$(echo "${METRICS[end_time]} - ${METRICS[start_time]}" | bc)
    METRICS[status]="${1:-SUCCESS}"
    
    log "info" "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"
    prepare_metrics_json METRICS > "$METRICS_LOG"
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è JSON
    if ! jq -e . "$METRICS_LOG" >/dev/null 2>&1; then
        log "error" "–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è JSON –º–µ—Ç—Ä–∏–∫"
        mv "$METRICS_LOG" "${METRICS_LOG}.invalid"
        jq -n --arg error "invalid_metrics" '{error: $error}' > "$METRICS_LOG"
    fi
}

send_telegram() {
    local message="$1"
    curl -s -X POST "$TG_API_URL" \
        -d chat_id="$TG_CHAT_ID" \
        -d text="$message" \
        -d parse_mode="Markdown" >/dev/null
}

check_dependencies() {
    local required=("tar" "pigz" "openssl" "obsutil" "split" "pg_dump" "psql" "jq")
    local missing=()
    
    for cmd in "${required[@]}"; do
        if ! command -v "$cmd" &>/dev/null; then
            missing+=("$cmd")
        fi
    done

    if [ ${#missing[@]} -gt 0 ]; then
        log "error" "–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: ${missing[*]}"
        send_telegram "*üö´ –û—à–∏–±–∫–∞: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏*: ${missing[*]}"
        exit 1
    fi
    log "info" "–í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–æ—Å—Ç—É–ø–Ω—ã"
}

prepare_environment() {
    mkdir -p "$DUMP_DIR" "$ARCHIVE_DIR" "$TMP_DIR"
    log "info" "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Ä–∞–±–æ—á–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"
    
    if [ -d "$TMP_DIR" ]; then
        rm -rf "${TMP_DIR:?}/"*
        log "info" "–û—á–∏—â–µ–Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: $TMP_DIR"
    fi
}

check_db_connection() {
    local start=$(date +%s.%N)
    log "info" "–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î ${DATABASE} –Ω–∞ ${DB_HOST}"
    
    export PGPASSWORD
    if psql -U "$DB_USER" -h "$DB_HOST" -p "$DB_PORT" -d "$DATABASE" -c "SELECT 1;" >/dev/null 2>>"${LOG_DIR}/db_connection.log"; then
        local duration=$(echo "$(date +%s.%N) - $start" | bc)
        log "info" "–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∑–∞ $(format_duration $duration) —Å–µ–∫"
        METRICS[db_connection]="success"
        METRICS[db_connection_duration]=$duration
    else
        log "error" "–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î"
        METRICS[db_connection]="failed"
        send_telegram "*üö´ –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î*"
        save_metrics "FAILED"
        exit 1
    fi
    unset PGPASSWORD
}

create_db_dump() {
    local start=$(date +%s.%N)
    log "info" "–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–º–ø–∞ –ë–î ${DATABASE}"
    
    export PGPASSWORD
    if pg_dump -U "$DB_USER" "$DATABASE" -h "$DB_HOST" -p "$DB_PORT" > "$SOURCE_DUMP" 2>>"${LOG_DIR}/pg_dump_error.log"; then
        local duration=$(echo "$(date +%s.%N) - $start" | bc)
        local size=$(du -h "$SOURCE_DUMP" | cut -f1)
        log "info" "–î–∞–º–ø —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –∑–∞ $(format_duration $duration) —Å–µ–∫, —Ä–∞–∑–º–µ—Ä: $size"
        METRICS[dump_size]="$size"
        METRICS[dump_duration]=$duration
    else
        log "error" "–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∞–º–ø–∞"
        send_telegram "*üö´ –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–º–ø–∞ –ë–î*"
        save_metrics "FAILED"
        exit 1
    fi
    unset PGPASSWORD
}

# ==================== –û–°–ù–û–í–ù–û–ô –ü–†–û–¶–ï–°–° ====================
main() {
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫
    declare -A METRICS=(
        [start_time]=$(date +%s.%N)
        [db_host]="$DB_HOST"
        [db_name]="$DATABASE"
        [backup_server]="$HOSTNAME"
        [config_file]="$CONFIG_FILE"
        [status]="RUNNING"
        [skip_dump]="$SKIP_DUMP"
        [skip_clean]="$SKIP_CLEAN"
        [dry_run]="$DRY_RUN"
    )

    trap 'log "error" "–°–∫—Ä–∏–ø—Ç –ø—Ä–µ—Ä–≤–∞–Ω"; save_metrics "FAILED"; exit 1' INT TERM
    
    log "info" "=== –ù–ê–ß–ê–õ–û –†–ï–ó–ï–†–í–ù–û–ì–û –ö–û–ü–ò–†–û–í–ê–ù–ò–Ø ==="
    log "info" "–•–æ—Å—Ç –ë–î: $DB_HOST"
    log "info" "–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: $DATABASE"
    log "info" "–°–µ—Ä–≤–µ—Ä —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è: $HOSTNAME"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    check_dependencies
    prepare_environment
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    if ! $SKIP_DUMP || $DRY_RUN; then
        check_db_connection
        if $DRY_RUN; then
            log "info" "Dry-run –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ"
            save_metrics "DRY_RUN"
            send_telegram "‚úÖ *Dry-run –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞*
*–•–æ—Å—Ç –ë–î:* \`${DB_HOST}\`
*–ë–î:* \`${DATABASE}\`
*–°—Ç–∞—Ç—É—Å:* –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ"
            exit 0
        fi
    fi
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–º–ø–∞
    if ! $SKIP_DUMP; then
        create_db_dump
    else
        log "info" "–ü—Ä–æ–ø—É—Å–∫ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–º–ø–∞ (–ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)"
        METRICS[skip_dump]="true"
    fi
    
    # [–û—Å—Ç–∞–ª—å–Ω—ã–µ —ç—Ç–∞–ø—ã —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è...]
    
    save_metrics "SUCCESS"
    log "info" "=== –†–ï–ó–ï–†–í–ù–û–ï –ö–û–ü–ò–†–û–í–ê–ù–ò–ï –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–û ==="
    
    send_telegram "‚úÖ *–†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ*
*–•–æ—Å—Ç –ë–î:* \`${DB_HOST}\`
*–ë–î:* \`${DATABASE}\`
*–°—Ç–∞—Ç—É—Å:* –£—Å–ø–µ—à–Ω–æ
*–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:* $(format_duration ${METRICS[duration]}) —Å–µ–∫"
}

# –ó–∞–ø—É—Å–∫
main "$@"